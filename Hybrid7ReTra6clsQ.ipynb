{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hybrid7ReTra6clsQ.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/mingweihe/HandGestureRecognition/blob/master/Hybrid7ReTra6clsQ.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "YJaLeZZIbe-B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "e198a829-2304-4a15-deff-f63d631942c0"
      },
      "cell_type": "code",
      "source": [
        "#------------------------------------------------\n",
        "#    Training and Test data set preparation\n",
        "#------------------------------------------------\n",
        "!rm -rf checkpoints && rm -rf *.zip\n",
        "!pip install -U -q PyDrive\n",
        "import os\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# 2. Downloading hafl trained model\n",
        "local_download_path = os.path.expanduser('~')\n",
        "file_list = drive.ListFile(\n",
        "    {'q': \"'19lVhhib3mhWMW_eQsFFoOQLVsmfN6SB3' in parents\"}).GetList()\n",
        "\n",
        "for f in file_list:\n",
        "  # 3. Create & download by id.\n",
        "  print('title: %s, id: %s' % (f['title'], f['id']))\n",
        "  fname = os.path.join(local_download_path, f['title'])\n",
        "  print('downloading to {}'.format(fname))\n",
        "  f_ = drive.CreateFile({'id': f['id']})\n",
        "  f_.GetContentFile(fname)\n",
        "\n",
        "!unzip /content/*.zip\n",
        "clear_output()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M8h00KEOGc-P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "73041e20-adef-48b6-b967-ea9503f6edf2"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lReNlvi6VZQV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "522aa53a-d3c6-4380-9e49-6ccd0521c26a"
      },
      "cell_type": "code",
      "source": [
        "# Set parameters\n",
        "chkp_dir = os.path.join('checkpoints', 'cnnGesture')\n",
        "chkp_name = 'model'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WtYcPcn7VZQY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "bbf6f58a-6dec-4bdf-bf38-fcaac5b6dbc9"
      },
      "cell_type": "code",
      "source": [
        "# images plotting function\n",
        "def plotImg(imgs, titles = None):\n",
        "    fig = plt.figure()\n",
        "    for i in range(len(imgs)):\n",
        "        ax = fig.add_subplot(1, len(imgs), i + 1)\n",
        "        if titles != None:\n",
        "            ax.title.set_text(titles[i])\n",
        "        plt.imshow(imgs[i])\n",
        "        plt.axis('off')\n",
        "    plt.show()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OSEdoLfqGdAV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ef03bcaf-4c4b-4b81-db3a-4176a7b4b0b7"
      },
      "cell_type": "code",
      "source": [
        "# restore checkpoint\n",
        "sessRes = tf.Session()\n",
        "saver = tf.train.import_meta_graph(os.path.join(chkp_dir, 'model.meta'))\n",
        "saver.restore(sessRes, tf.train.latest_checkpoint(chkp_dir))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from checkpoints/cnnGesture/model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SqvCis4YHpSX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "f2b04f7c-bb7e-4750-dab9-d77f1bd3007b"
      },
      "cell_type": "code",
      "source": [
        "# variable and tensor initialization\n",
        "img_holder = sessRes.graph.get_tensor_by_name('img_holder:0')\n",
        "lbl_holder =sessRes.graph.get_tensor_by_name('lbl_holder:0')\n",
        "loss=sessRes.graph.get_tensor_by_name('loss:0')\n",
        "accuracy=tf.get_default_graph().get_tensor_by_name('accuracy:0')\n",
        "optimizer=tf.get_default_graph().get_tensor_by_name('optimizer:0')\n",
        "predict=tf.get_default_graph().get_tensor_by_name('prediction:0')\n",
        "train = sessRes.graph.get_tensor_by_name('train_bool:0')\n",
        "log_dir = sessRes.run('log_dir:0').decode('utf-8')\n",
        "test_total = sessRes.run('test_total:0')\n",
        "train_total = sessRes.run('train_total:0')\n",
        "num_epochs = sessRes.run('num_epochs:0')\n",
        "batch_size = sessRes.run('batch_size:0')\n",
        "global_step = sessRes.run('global_step:0')\n",
        "global_epoch = int(global_step*batch_size/train_total)\n",
        "# # tensorboard\n",
        "# summary_loss = tf.summary.scalar('loss', loss)\n",
        "# summary_accuracy = tf.summary.scalar('accuracy', accuracy)\n",
        "# merged_op = tf.summary.merge([summary_loss, summary_accuracy])\n",
        "# # Create FileWriter\n",
        "# file_writer = tf.summary.FileWriter(log_dir, graph=tf.get_default_graph())\n",
        "print('number of epoch for each training:', num_epochs)\n",
        "print('batch size of each step:', batch_size)\n",
        "print('total test set:', test_total)\n",
        "print('total train set:', train_total)\n",
        "print('global steps:', global_step)\n",
        "print('global epochs:', global_epoch)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of epoch for each training: 20\n",
            "batch size of each step: 10\n",
            "total test set: 369\n",
            "total train set: 12000\n",
            "global steps: 72500\n",
            "global epochs: 60\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "u1LGYolfIZSd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7f75967c-f894-4098-a264-cbe9b43c8819"
      },
      "cell_type": "code",
      "source": [
        "# session to exexute queuing\n",
        "# restore checkpoint\n",
        "sess4Q = tf.Session()\n",
        "saver4Q = tf.train.import_meta_graph(os.path.join(chkp_dir, 'model.meta'))\n",
        "saver4Q.restore(sess4Q, tf.train.latest_checkpoint(chkp_dir))\n",
        "batchTrainData = sess4Q.graph.get_tensor_by_name('batchTrainData:0')\n",
        "batchTrainLabel = sess4Q.graph.get_tensor_by_name('batchTrainData:1')\n",
        "totalTestData = sess4Q.graph.get_tensor_by_name('totalTestData:0')\n",
        "totalTestLabel = sess4Q.graph.get_tensor_by_name('totalTestData:1')\n",
        "sess4Q.run(tf.local_variables_initializer())\n",
        "coord=tf.train.Coordinator()\n",
        "threads=tf.train.start_queue_runners(sess=sess4Q,coord=coord)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from checkpoints/cnnGesture/model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Mj40oy8Oev6O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 640
        },
        "outputId": "70f3fd55-dd20-4ce7-c98d-f6a8272ce46d"
      },
      "cell_type": "code",
      "source": [
        "try:\n",
        "    test_images,test_labels = sess4Q.run([totalTestData, totalTestLabel])\n",
        "    batch_i = 1\n",
        "    total_batch = 0\n",
        "    local_epoch = 1\n",
        "    start_time = time.time()\n",
        "    while not coord.should_stop():\n",
        "        imgs, labels = sess4Q.run([batchTrainData,batchTrainLabel])\n",
        "        sessRes.run(optimizer, feed_dict={img_holder:imgs,lbl_holder:labels,train: True})\n",
        "#         loss_val, accuracy_val, summary = sessRes.run([loss, accuracy, merged_op],feed_dict={img_holder:imgs,lbl_holder:labels,train: False})\n",
        "#         # Print the summary data\n",
        "#         file_writer.add_summary(summary)\n",
        "        if batch_i % 100 == 0:\n",
        "            loss_val, accuracy_val = sessRes.run([loss, accuracy],feed_dict={img_holder:imgs,lbl_holder:labels,train: False})\n",
        "            test_accuracy = sessRes.run(accuracy, feed_dict={img_holder:test_images[269:369],lbl_holder:test_labels[269:369],train: False})\n",
        "#             file_writer.flush()\n",
        "            duration = time.time() - start_time\n",
        "            print('epoch:', str(local_epoch)+ '/' +str(num_epochs), 'batch:', batch_i, 'loss:', \n",
        "                  loss_val, 'cur_accuracy:', accuracy_val, 'test_accuracy:', test_accuracy, 'duration: %.3fs' % duration)\n",
        "            start_time = time.time()\n",
        "        batch_i += 1\n",
        "        total_batch += batch_size\n",
        "        if total_batch >= train_total:\n",
        "            local_epoch += 1\n",
        "            total_batch = 0\n",
        "            batch_i = 1\n",
        "except tf.errors.OutOfRangeError:\n",
        "    print('Done.')\n",
        "except Exception as e:\n",
        "    coord.request_stop(e)\n",
        "finally:\n",
        "    coord.request_stop()\n",
        "coord.join(threads)\n",
        "sess4Q.close()\n",
        "# save training result\n",
        "saver.save(sessRes, os.path.join(chkp_dir, chkp_name))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 1/20 batch: 100 loss: 0.0 cur_accuracy: 1.0 test_accuracy: 0.75 duration: 25.099s\n",
            "epoch: 1/20 batch: 200 loss: 136.96063 cur_accuracy: 0.7 test_accuracy: 0.61 duration: 18.603s\n",
            "epoch: 1/20 batch: 300 loss: 90.23013 cur_accuracy: 0.7 test_accuracy: 0.66 duration: 18.744s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-f204184d9b22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcoord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess4Q\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatchTrainData\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatchTrainLabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0msessRes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mimg_holder\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlbl_holder\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;31m#         loss_val, accuracy_val, summary = sessRes.run([loss, accuracy, merged_op],feed_dict={img_holder:imgs,lbl_holder:labels,train: False})\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#         # Print the summary data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1102\u001b[0m             \u001b[0mfeed_handles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubfeed_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m             \u001b[0mnp_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubfeed_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m           if (not is_tensor_handle_feed and\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m     \"\"\"\n\u001b[0;32m--> 492\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "xG409xEyGdAW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "begin = random.randrange(0, test_total-10)\n",
        "end = begin + 10\n",
        "res, accuracy_val = sessRes.run([predict, accuracy], feed_dict = {img_holder: test_images[begin:end], lbl_holder:test_labels[begin:end], train: False})\n",
        "titles = [str(np.argmax(test_labels[i])) + '->' + str(res[i-begin]) for i in range(begin, end)] \n",
        "plotImg(test_images[begin:end], titles)\n",
        "print('Accuracy:', accuracy_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QKzVBejXTsYG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sessRes.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "STIvxtMuGdAc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# # memory footprint support libraries/code\n",
        "# !ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "# !pip install gputil\n",
        "# !pip install psutil\n",
        "# !pip install humanize\n",
        "# import psutil\n",
        "# import humanize\n",
        "# import os\n",
        "# import GPUtil as GPU\n",
        "# GPUs = GPU.getGPUs()\n",
        "# # XXX: only one GPU on Colab and isnâ€™t guaranteed\n",
        "# gpu = GPUs[0]\n",
        "# def printm():\n",
        "#  process = psutil.Process(os.getpid())\n",
        "#  print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" I Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        "#  print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "# printm()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VNY_y6KMNlrf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#------------------------------------------------\n",
        "#    Replace google drive trained model with new one\n",
        "#------------------------------------------------\n",
        "!rm -rf Hybrid7.zip\n",
        "!zip -r Hybrid7.zip checkpoints\n",
        "# Install the PyDrive wrapper & import libraries.\n",
        "# This only needs to be done once in a notebook.\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once in a notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "file_list = drive.ListFile(\n",
        "    {'q': \"'19lVhhib3mhWMW_eQsFFoOQLVsmfN6SB3' in parents\"}).GetList()\n",
        "\n",
        "for f in file_list:\n",
        "  # delete old one\n",
        "  fname = f['title']\n",
        "  print('Deleting', fname)\n",
        "  f.Delete()\n",
        "file_metadata = {'title': 'Hybrid7.zip', \"parents\": [{\"id\": '19lVhhib3mhWMW_eQsFFoOQLVsmfN6SB3', \"kind\": \"drive#childList\"}]}\n",
        "# Create & upload a file.\n",
        "uploaded = drive.CreateFile(file_metadata)\n",
        "uploaded.SetContentFile('Hybrid7.zip')\n",
        "uploaded.Upload()\n",
        "print('Uploaded file with ID {}'.format(uploaded.get('id')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LAGbyy4ltk56",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}