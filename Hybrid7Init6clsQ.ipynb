{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hybrid7Init6clsQ.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/mingweihe/HandGestureRecognition/blob/master/Hybrid7Init6clsQ.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "M8h00KEOGc-P",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lReNlvi6VZQV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title\n",
        "# Set parameters\n",
        "image_height = 300\n",
        "image_width = 370\n",
        "num_channels = 3\n",
        "num_categories = 6\n",
        "num_filters1 = 32\n",
        "num_filters2 = 64\n",
        "num_filters3 = 64\n",
        "num_filters4 = 128\n",
        "num_filters5 = 256\n",
        "num_filters6 = 512\n",
        "num_filters7 = 1024\n",
        "filter_size = 3\n",
        "num_epochs = 20\n",
        "batch_size = 100\n",
        "pooling_size = 2\n",
        "fully_connected_size = 1024\n",
        "log_dir = os.path.join('log', 'cnnGesture')\n",
        "chkp_dir = os.path.join('checkpoints', 'cnnGesture')\n",
        "chkp_name = 'model'\n",
        "learning_rate = 5e-4\n",
        "min_after_dequeue = 1000\n",
        "capacity=min_after_dequeue+3*batch_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6efJF9O-kmzf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e9e45ae5-b42e-4bdc-d5bb-b1b490f1ede9"
      },
      "cell_type": "code",
      "source": [
        "tf.Variable(num_epochs, name='num_epochs')\n",
        "tf.Variable(batch_size, name='batch_size')\n",
        "tf.Variable(log_dir, name='log_dir')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'log_dir:0' shape=() dtype=string_ref>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "WtYcPcn7VZQY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# images plotting function\n",
        "def plotImg(imgs, titles = None):\n",
        "    fig = plt.figure()\n",
        "    for i in range(len(imgs)):\n",
        "        ax = fig.add_subplot(1, len(imgs), i + 1)\n",
        "        if titles != None:\n",
        "            ax.title.set_text(titles[i])\n",
        "        plt.imshow(imgs[i])\n",
        "        plt.axis('off')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Tn77Tbr4VZQZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "reader=tf.TFRecordReader()\n",
        "fmt = {'image_raw':tf.FixedLenFeature([],tf.string), 'label':tf.FixedLenFeature([],tf.int64)}\n",
        "fmt1 = {'size':tf.FixedLenFeature([],tf.int64)}\n",
        "# read train set graph\n",
        "train_queue=tf.train.string_input_producer(['Records/train.tfrecords'], num_epochs=num_epochs, shuffle=True, name='train_queue')   \n",
        "_,serialized_train_set=reader.read(train_queue)\n",
        "train_features=tf.parse_single_example(serialized_train_set, features=fmt)\n",
        "train_images=tf.decode_raw(train_features['image_raw'],tf.uint8)\n",
        "train_images=tf.reshape(train_images,[image_height,image_width,num_channels])\n",
        "train_labels=tf.cast(train_features['label'],tf.int32)\n",
        "train_labels=tf.one_hot(train_labels, num_categories, on_value=1.0, off_value=0.0, dtype=tf.float32)\n",
        "\n",
        "train_queue1=tf.train.string_input_producer(['Records/train.meta'])\n",
        "_,serialized_train_set1=reader.read(train_queue1)\n",
        "train_features1=tf.parse_single_example(serialized_train_set1, features=fmt1)\n",
        "train_total=tf.cast(train_features1['size'],tf.int32)\n",
        "\n",
        "# read test set graph\n",
        "test_queue=tf.train.string_input_producer(['Records/test.tfrecords'])\n",
        "_,serialized_test_set=reader.read(test_queue)\n",
        "test_features=tf.parse_single_example(serialized_test_set,features=fmt)\n",
        "test_images=tf.decode_raw(test_features['image_raw'],tf.uint8)\n",
        "test_images=tf.reshape(test_images,[image_height,image_width,num_channels])\n",
        "test_labels=tf.cast(test_features['label'],tf.int32)\n",
        "test_labels=tf.one_hot(test_labels, num_categories, on_value=1.0, off_value=0.0, dtype=tf.float32)\n",
        "\n",
        "test_queue1=tf.train.string_input_producer(['Records/test.meta'])\n",
        "_,serialized_test_set1=reader.read(test_queue1)\n",
        "test_features1=tf.parse_single_example(serialized_test_set1,features=fmt1)\n",
        "test_total=tf.cast(test_features1['size'],tf.int32)\n",
        "\n",
        "sess=tf.Session()\n",
        "sess.run(tf.local_variables_initializer())\n",
        "coord=tf.train.Coordinator()\n",
        "threads=tf.train.start_queue_runners(sess=sess,coord=coord)\n",
        "train_total,test_total=sess.run([train_total,test_total])\n",
        "coord.request_stop()\n",
        "sess.close()\n",
        "\n",
        "tf.Variable(train_total, name='train_total')\n",
        "tf.Variable(test_total, name='test_total')\n",
        "\n",
        "# batch train set queue graph\n",
        "train_images_batch,train_label_batch=tf.train.shuffle_batch([train_images,train_labels],batch_size=batch_size,\n",
        "capacity=capacity,min_after_dequeue=min_after_dequeue, name='batchTrainData')\n",
        "\n",
        "# total test set queue graph\n",
        "test_images_batch,test_label_batch=tf.train.shuffle_batch([test_images,test_labels],batch_size=test_total,\n",
        "capacity=capacity,min_after_dequeue=min_after_dequeue, name='totalTestData')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fLopZmdKGc-k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Placeholders for images\n",
        "img_holder = tf.placeholder(tf.float32, [None, image_height, image_width,\n",
        "num_channels], name = 'img_holder')\n",
        "lbl_holder = tf.placeholder(tf.int8, [None, num_categories], name = 'lbl_holder')\n",
        "train = tf.placeholder(tf.bool, name = 'train_bool')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xds5-TaMPx1J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Preprocess the image, Performs random transformations\n",
        "# Random flip left and right\n",
        "img_tensor_flip = tf.map_fn(lambda img: tf.image.random_flip_left_right(img), img_holder)\n",
        "# Random flip up and down \n",
        "img_tensor_flip1 = tf.map_fn(lambda img: tf.image.random_flip_up_down(img), img_tensor_flip)\n",
        "# Random brightness\n",
        "img_tensor_bri = tf.map_fn(lambda img: tf.image.random_brightness(img, max_delta=0.2), img_tensor_flip1)\n",
        "# Per-image scaling\n",
        "img_tensor_std = tf.map_fn(lambda img: tf.image.per_image_standardization(img), img_tensor_bri)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FC6Yn9gPGc-o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "eea0a4e7-d64f-4664-dcdd-78463a5a4187"
      },
      "cell_type": "code",
      "source": [
        "# Create convolution/pooling layers\n",
        "conv1 = tf.layers.conv2d(img_tensor_std, num_filters1, filter_size, padding='same', \\\n",
        "activation=tf.nn.relu, name = 'conv1')\n",
        "print(np.shape(img_tensor_std))\n",
        "print(np.shape(conv1))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(?, 300, 370, 3)\n",
            "(?, 300, 370, 32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hILT35AmGc-v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3b8fb432-08a3-41b8-80c3-b39b6587f6f6"
      },
      "cell_type": "code",
      "source": [
        "pool1 = tf.layers.max_pooling2d(conv1, pooling_size, pooling_size, name = 'pool1')\n",
        "print(np.shape(pool1))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(?, 150, 185, 32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gXBCdNT4Gc-y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "conv2 = tf.layers.conv2d(pool1, num_filters2, filter_size, padding='same',\n",
        "activation=tf.nn.relu, name = 'conv2')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "af_jYprGGc-4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7ee637af-bf66-4e62-e2ad-bf85ec2cfd76"
      },
      "cell_type": "code",
      "source": [
        "pool2 = tf.layers.max_pooling2d(conv2, pooling_size, pooling_size, name = 'pool2')\n",
        "print(np.shape(pool2))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(?, 75, 92, 64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GkKANPaYGc-7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "conv3 = tf.layers.conv2d(pool2, num_filters3, filter_size, padding='same',\n",
        "activation=tf.nn.relu, name = 'conv3')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rb5tv6azGc--",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4c930dee-5f38-49c3-c2f0-de330d48d805"
      },
      "cell_type": "code",
      "source": [
        "pool3 = tf.layers.max_pooling2d(conv3, pooling_size, pooling_size, name = 'pool3')\n",
        "print(np.shape(pool3))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(?, 37, 46, 64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Oeqmx6_lGc_C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "conv4 = tf.layers.conv2d(pool3, num_filters4, filter_size, padding='same',\n",
        "activation=tf.nn.relu, name = 'conv4')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Teh4q6fDu7Yd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "conv5 = tf.layers.conv2d(conv4, num_filters5, filter_size, padding='same',\n",
        "activation=tf.nn.relu, name = 'conv5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "payynk9jmKcj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e21417f2-a8c0-470b-be78-9ae570acf718"
      },
      "cell_type": "code",
      "source": [
        "pool4 = tf.layers.max_pooling2d(conv5, pooling_size, pooling_size, name = 'pool4')\n",
        "print(np.shape(pool4))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(?, 18, 23, 256)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "b3E6VPEuvUxG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "conv6 = tf.layers.conv2d(pool4, num_filters6, filter_size, padding='same',\n",
        "activation=tf.nn.relu, name = 'conv6')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Dk9jbl9XvYy0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ae58c4ed-a15d-4016-c9b7-7ce7ce635936"
      },
      "cell_type": "code",
      "source": [
        "pool5 = tf.layers.max_pooling2d(conv6, pooling_size, pooling_size, name = 'pool5')\n",
        "print(np.shape(pool5))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(?, 9, 11, 512)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "e-BVfCxTRUJ2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "conv7 = tf.layers.conv2d(pool5, num_filters7, filter_size, padding='same',\n",
        "activation=tf.nn.relu, name = 'conv7')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lCX_rkGsRUxI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "050aa130-8313-400b-e61d-91805b88e282"
      },
      "cell_type": "code",
      "source": [
        "pool6 = tf.layers.average_pooling2d(conv7, 9, 11, name = 'pool6')\n",
        "print(np.shape(pool6))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(?, 1, 1, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7HXR01AbGc_N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "541967fe-9d29-4469-9f22-cbc2fe3229f3"
      },
      "cell_type": "code",
      "source": [
        "# Flatten input data\n",
        "flatten = tf.reshape(pool6, [-1, fully_connected_size], name = 'flatten')\n",
        "print(np.shape(flatten))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(?, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lJ8HnWM6Gc_P",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create connected layers\n",
        "with tf.contrib.framework.arg_scope(\n",
        "[tf.contrib.layers.fully_connected],\n",
        "normalizer_fn=tf.contrib.layers.batch_norm,\n",
        "normalizer_params={'is_training': train}):\n",
        "    fc1 = tf.contrib.layers.fully_connected(flatten, fully_connected_size, scope = 'fc1')\n",
        "    fc2 = tf.contrib.layers.fully_connected(fc1, num_categories,\n",
        "    activation_fn=None, scope = 'fc2')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3GhZa8XPGc_S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "1c1df5b9-a48f-4e1d-8d97-11ba8e38d668"
      },
      "cell_type": "code",
      "source": [
        "# Compute loss\n",
        "loss = tf.reduce_mean(\n",
        "tf.nn.softmax_cross_entropy_with_logits(\n",
        "logits=fc2, labels=lbl_holder), name = 'loss')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-23-5d7a5c5e4aa4>:3: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PsZi4MxAGc_W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create optimizer\n",
        "global_step = tf.Variable(0, name='global_step', trainable=False)\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss, name = 'optimizer', global_step = global_step)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nGSCQlz_Gc_Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Determine success rate\n",
        "prediction = tf.argmax(fc2, 1, name = 'prediction')\n",
        "correct_pred = tf.equal(prediction, tf.argmax(lbl_holder, 1), name = 'correct_pred')\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name = 'accuracy')\n",
        "# probabilities of each class\n",
        "probabilities = tf.nn.softmax(fc2, name='probabilities')\n",
        "# # tensorboard\n",
        "# summary_loss=tf.summary.scalar('loss', loss)\n",
        "# summary_accuracy=tf.summary.scalar('accuracy', accuracy)\n",
        "# merged_op = tf.summary.merge([summary_loss, summary_accuracy])\n",
        "# # Create FileWriter\n",
        "# file_writer = tf.summary.FileWriter(log_dir, graph=tf.get_default_graph())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FcSbtSUKGc_b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# session and variable initialize\n",
        "sess=tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "sess.run(tf.local_variables_initializer())\n",
        "coord=tf.train.Coordinator()\n",
        "threads=tf.train.start_queue_runners(sess=sess,coord=coord)\n",
        "# saver for storing training result\n",
        "saver = tf.train.Saver()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3guNjGGZVZRc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4077
        },
        "outputId": "9c8abdef-1e46-44d5-8be3-a9dc2eacef9a"
      },
      "cell_type": "code",
      "source": [
        "try:\n",
        "    test_images,test_labels = sess.run([test_images_batch, test_label_batch])\n",
        "    batch_i = 1\n",
        "    total_batch = 0\n",
        "    epoch = 1\n",
        "    start_time = time.time()\n",
        "    while not coord.should_stop():\n",
        "        imgs, labels = sess.run([train_images_batch, train_label_batch])\n",
        "        sess.run(optimizer, feed_dict={img_holder:imgs,lbl_holder:labels,train: True})\n",
        "#         # record the summary to the log file\n",
        "#         summary = sess.run(merged_op, feed_dict={img_holder:imgs,lbl_holder:labels,train: False})\n",
        "#         file_writer.add_summary(summary)\n",
        "#         file_writer.flush()\n",
        "        if batch_i % 100 == 0:\n",
        "            loss_val, accuracy_val = sess.run([loss, accuracy], feed_dict={img_holder:imgs,lbl_holder:labels,train: False})\n",
        "            test_accuracy = sess.run(accuracy, feed_dict={img_holder:test_images,lbl_holder:test_labels,train: False})\n",
        "            # save training result\n",
        "            saver.save(sess, os.path.join(chkp_dir, chkp_name))\n",
        "            duration = time.time() - start_time\n",
        "            print('epoch:', epoch, 'batch:', batch_i, 'loss:', loss_val, 'cur_accuracy:', accuracy_val, 'test_accuracy:', test_accuracy, \n",
        "                  'duration: %.3fs' % duration)\n",
        "            start_time = time.time()\n",
        "        batch_i += 1\n",
        "        total_batch += batch_size\n",
        "        if total_batch >= train_total:\n",
        "            epoch += 1\n",
        "            total_batch = 0\n",
        "            batch_i = 1\n",
        "except tf.errors.OutOfRangeError:\n",
        "    print('Done.')\n",
        "except Exception as e:\n",
        "    coord.request_stop(e)\n",
        "finally:\n",
        "    coord.request_stop()\n",
        "coord.join(threads)\n",
        "sess.close()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.ResourceExhaustedError'>, OOM when allocating tensor with shape[300,370,3] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
            "\t [[Node: map/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3 = TensorArrayScatterV3[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](map/TensorArray, map/TensorArrayUnstack/range, _arg_img_holder_0_0/_95, map/TensorArray:1)]]\n",
            "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
            "\n",
            "\n",
            "Caused by op 'map/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3', defined at:\n",
            "  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
            "    \"__main__\", mod_spec)\n",
            "  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
            "    app.launch_new_instance()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
            "    app.start()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n",
            "    ioloop.IOLoop.instance().start()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/ioloop.py\", line 177, in start\n",
            "    super(ZMQIOLoop, self).start()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 888, in start\n",
            "    handler_func(fd_obj, events)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n",
            "    self._handle_recv()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n",
            "    self._run_callback(callback, msg)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n",
            "    callback(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n",
            "    return self.dispatch_shell(stream, msg)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n",
            "    handler(stream, idents, msg)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n",
            "    user_expressions, allow_stdin)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n",
            "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n",
            "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n",
            "    interactivity=interactivity, compiler=compiler, result=result)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n",
            "    if self.run_code(code, result):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-7-25fb1797613e>\", line 1, in <module>\n",
            "    img_tensor_flip = tf.map_fn(lambda img: tf.image.random_flip_left_right(img), img_holder)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/functional_ops.py\", line 423, in map_fn\n",
            "    elem_ta.unstack(elem) for elem_ta, elem in zip(elems_ta, elems_flat)]\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/functional_ops.py\", line 423, in <listcomp>\n",
            "    elem_ta.unstack(elem) for elem_ta, elem in zip(elems_ta, elems_flat)]\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/tf_should_use.py\", line 118, in wrapped\n",
            "    return _add_should_use_warning(fn(*args, **kwargs))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/tensor_array_ops.py\", line 907, in unstack\n",
            "    return self._implementation.unstack(value, name=name)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/tf_should_use.py\", line 118, in wrapped\n",
            "    return _add_should_use_warning(fn(*args, **kwargs))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/tensor_array_ops.py\", line 331, in unstack\n",
            "    indices=math_ops.range(0, num_elements), value=value, name=name)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/tf_should_use.py\", line 118, in wrapped\n",
            "    return _add_should_use_warning(fn(*args, **kwargs))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/tensor_array_ops.py\", line 347, in scatter\n",
            "    name=name)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_data_flow_ops.py\", line 6590, in tensor_array_scatter_v3\n",
            "    flow_in=flow_in, name=name)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n",
            "    op_def=op_def)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3414, in create_op\n",
            "    op_def=op_def)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 1740, in __init__\n",
            "    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n",
            "\n",
            "ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[300,370,3] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
            "\t [[Node: map/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3 = TensorArrayScatterV3[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](map/TensorArray, map/TensorArrayUnstack/range, _arg_img_holder_0_0/_95, map/TensorArray:1)]]\n",
            "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[300,370,3] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: map/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3 = TensorArrayScatterV3[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](map/TensorArray, map/TensorArrayUnstack/range, _arg_img_holder_0_0/_95, map/TensorArray:1)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-7073ce3924a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mcoord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mcoord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthreads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/coordinator.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, threads, stop_grace_period_secs, ignore_live_threads)\u001b[0m\n\u001b[1;32m    387\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_registered_threads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exc_info_to_raise\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m         \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exc_info_to_raise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m       \u001b[0;32melif\u001b[0m \u001b[0mstragglers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mignore_live_threads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-7073ce3924a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcoord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_images_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_label_batch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mimg_holder\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlbl_holder\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;31m#         # record the summary to the log file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#         summary = sess.run(merged_op, feed_dict={img_holder:imgs,lbl_holder:labels,train: False})\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[300,370,3] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: map/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3 = TensorArrayScatterV3[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](map/TensorArray, map/TensorArrayUnstack/range, _arg_img_holder_0_0/_95, map/TensorArray:1)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'map/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3', defined at:\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-7-25fb1797613e>\", line 1, in <module>\n    img_tensor_flip = tf.map_fn(lambda img: tf.image.random_flip_left_right(img), img_holder)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/functional_ops.py\", line 423, in map_fn\n    elem_ta.unstack(elem) for elem_ta, elem in zip(elems_ta, elems_flat)]\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/functional_ops.py\", line 423, in <listcomp>\n    elem_ta.unstack(elem) for elem_ta, elem in zip(elems_ta, elems_flat)]\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/tf_should_use.py\", line 118, in wrapped\n    return _add_should_use_warning(fn(*args, **kwargs))\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/tensor_array_ops.py\", line 907, in unstack\n    return self._implementation.unstack(value, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/tf_should_use.py\", line 118, in wrapped\n    return _add_should_use_warning(fn(*args, **kwargs))\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/tensor_array_ops.py\", line 331, in unstack\n    indices=math_ops.range(0, num_elements), value=value, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/tf_should_use.py\", line 118, in wrapped\n    return _add_should_use_warning(fn(*args, **kwargs))\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/tensor_array_ops.py\", line 347, in scatter\n    name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_data_flow_ops.py\", line 6590, in tensor_array_scatter_v3\n    flow_in=flow_in, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3414, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 1740, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[300,370,3] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: map/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3 = TensorArrayScatterV3[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](map/TensorArray, map/TensorArrayUnstack/range, _arg_img_holder_0_0/_95, map/TensorArray:1)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "OSEdoLfqGdAV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# restore checkpoint\n",
        "sessRes = tf.Session()\n",
        "saver = tf.train.import_meta_graph(os.path.join(chkp_dir, 'model.meta'))\n",
        "saver.restore(sessRes, tf.train.latest_checkpoint(chkp_dir))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SqvCis4YHpSX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# test data prediction randomly\n",
        "img_holder = sessRes.graph.get_tensor_by_name('img_holder:0')\n",
        "lbl_holder =sessRes.graph.get_tensor_by_name('lbl_holder:0')\n",
        "predict=tf.get_default_graph().get_tensor_by_name('prediction:0')\n",
        "accuracy=tf.get_default_graph().get_tensor_by_name('accuracy:0')\n",
        "train = sessRes.graph.get_tensor_by_name('train_bool:0')\n",
        "test_total = sessRes.run('test_total:0')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u1LGYolfIZSd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# session to exexute queuing\n",
        "# restore checkpoint\n",
        "sess4Q = tf.Session()\n",
        "saver4Q = tf.train.import_meta_graph(os.path.join(chkp_dir, 'model.meta'))\n",
        "saver4Q.restore(sess4Q, tf.train.latest_checkpoint(chkp_dir))\n",
        "sess4Q.run(tf.global_variables_initializer())\n",
        "sess4Q.run(tf.local_variables_initializer())\n",
        "coord=tf.train.Coordinator()\n",
        "threads=tf.train.start_queue_runners(sess=sess4Q,coord=coord)\n",
        "# batchTrainData = sess4Q.graph.get_tensor_by_name('batchTrainData:0')\n",
        "# batchTrainLabel = sess4Q.graph.get_tensor_by_name('batchTrainData:1')\n",
        "totalTestData = sess4Q.graph.get_tensor_by_name('totalTestData:0')\n",
        "totalTestLabel = sess4Q.graph.get_tensor_by_name('totalTestData:1')\n",
        "images,labels = sess4Q.run([totalTestData,totalTestLabel])\n",
        "# reason stop here is we use queue to get test set within one time 'coz we are only tesing training result here. \n",
        "coord.request_stop()\n",
        "sess4Q.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xG409xEyGdAW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "begin = random.randrange(0, test_total-10)\n",
        "end = begin + 10\n",
        "print(begin, end)\n",
        "res, accuracy_val = sessRes.run([predict, accuracy], feed_dict = {img_holder: images[begin:end], lbl_holder:labels[begin:end], train: False})\n",
        "titles = [str(np.argmax(labels[i])) + '->' + str(res[i-begin]) for i in range(begin, end)] \n",
        "plotImg(images[begin:end], titles)\n",
        "print('Accuracy:', accuracy_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QKzVBejXTsYG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sessRes.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "STIvxtMuGdAc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "634d5223-1438-46e8-cf68-3a8b7411cce2"
      },
      "cell_type": "code",
      "source": [
        "# # memory footprint support libraries/code\n",
        "# !ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "# !pip install gputil\n",
        "# !pip install psutil\n",
        "# !pip install humanize\n",
        "# import psutil\n",
        "# import humanize\n",
        "# import os\n",
        "# import GPUtil as GPU\n",
        "# GPUs = GPU.getGPUs()\n",
        "# # XXX: only one GPU on Colab and isn’t guaranteed\n",
        "# gpu = GPUs[0]\n",
        "# def printm():\n",
        "#  process = psutil.Process(os.getpid())\n",
        "#  print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" I Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        "#  print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "# printm()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gputil in /usr/local/lib/python3.6/dist-packages (1.3.0)\r\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from gputil) (1.14.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.6)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
            "Gen RAM Free: 11.7 GB  I Proc size: 137.5 MB\n",
            "GPU RAM Free: 564MB | Used: 10875MB | Util  95% | Total 11439MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VNY_y6KMNlrf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#------------------------------------------------\n",
        "#    Replace google drive trained model with new one\n",
        "#------------------------------------------------\n",
        "!rm -rf Hybrid7.zip\n",
        "!zip -r Hybrid7.zip checkpoints\n",
        "# Install the PyDrive wrapper & import libraries.\n",
        "# This only needs to be done once in a notebook.\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once in a notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "file_list = drive.ListFile(\n",
        "    {'q': \"'19lVhhib3mhWMW_eQsFFoOQLVsmfN6SB3' in parents\"}).GetList()\n",
        "\n",
        "for f in file_list:\n",
        "  # delete old one\n",
        "  fname = f['title']\n",
        "  print('Deleting', fname)\n",
        "  f.Delete()\n",
        "file_metadata = {'title': 'Hybrid7.zip', \"parents\": [{\"id\": '19lVhhib3mhWMW_eQsFFoOQLVsmfN6SB3', \"kind\": \"drive#childList\"}]}\n",
        "# Create & upload a file.\n",
        "uploaded = drive.CreateFile(file_metadata)\n",
        "uploaded.SetContentFile('Hybrid7.zip')\n",
        "uploaded.Upload()\n",
        "print('Uploaded file with ID {}'.format(uploaded.get('id')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LAGbyy4ltk56",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}